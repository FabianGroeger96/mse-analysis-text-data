{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnTeDe Lab 3: Sentiment Analysis - Part C\n",
    "\n",
    "## Session goal\n",
    "The goal of this session is to run document-level sentiment analysis on the IMDB movie review corpus by applying supervised text classification techniques. We begin by wrangling the IMBD corpus into lists, exactly like in 3b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random, nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "\n",
    "corpus = [' '.join(movie_reviews.words(fileid)) \\\n",
    "          for category in movie_reviews.categories() \\\n",
    "          for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "labels = [category \\\n",
    "          for category in movie_reviews.categories() \\\n",
    "          for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**scikit-learn** enables us the split the corpus into a training corpus and a test corpus. The parameter *test-size* is the desired ratio of the test corpus size to the training corpus size. The paramenter *random_state* ensures reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus, test_corpus, training_labels, test_labels = train_test_split(\n",
    "        corpus, labels, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reuse our helper function **get_metrics** from Lab 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(true_labels, predicted_labels):\n",
    "    print ('Accuracy:', np.round(\n",
    "        metrics.accuracy_score(true_labels, predicted_labels), 3))\n",
    "    print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to use a MNB classifier for sentiment analysis. **CountVectorizer**'s parameter **binary** replaces token counts with binary values if set to True. In sentiment analysis, the number of occurrences of a token may not be as important as its presence or absence, so setting it to True may be a good idea, but let's perform 10-fold cross-validation to find out whether it really is. We want the mean to be as high as possible and the standard deviation to be as low as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.802\n",
      "0.023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb_pipeline_1 = Pipeline([ \n",
    "    ('vectorizer', CountVectorizer(binary = False, stop_words='english')),\n",
    "    ('classifier', MultinomialNB())])  \n",
    "    \n",
    "scores = cross_val_score(mnb_pipeline_1, training_corpus, training_labels, cv=10)\n",
    "print (round(np.mean(scores), 3))\n",
    "print (round(np.std(scores), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.833\n",
      "0.028\n"
     ]
    }
   ],
   "source": [
    "mnb_pipeline_2 = Pipeline([ \n",
    "    ('vectorizer', CountVectorizer(binary = True, stop_words='english')),\n",
    "    ('classifier', MultinomialNB())])  \n",
    "    \n",
    "scores = cross_val_score(mnb_pipeline_2, training_corpus, training_labels, cv=10)\n",
    "print (round(np.mean(scores), 3))\n",
    "print (round(np.std(scores), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your 10-fold cross-validation results, choose one of the two pipelines, train it, run it, and analyze its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.83      0.81      0.82       198\n",
      "         pos       0.82      0.84      0.83       202\n",
      "\n",
      "    accuracy                           0.82       400\n",
      "   macro avg       0.83      0.82      0.82       400\n",
      "weighted avg       0.83      0.82      0.82       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb_pipeline_2.fit(training_corpus, training_labels) \n",
    "predicted_labels = mnb_pipeline_2.predict(test_corpus)\n",
    "get_metrics(true_labels=test_labels, predicted_labels=predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a Maximum Entropy classifier using the **LogisticRegression** module from **scikit-learn**. Please complete the code to train and run the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.80      0.82       198\n",
      "         pos       0.82      0.86      0.84       202\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.83      0.83      0.83       400\n",
      "weighted avg       0.83      0.83      0.83       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "vectorizer = CountVectorizer(binary = True, stop_words='english')\n",
    "classifier = LogisticRegression()\n",
    "maxent_pipeline = make_pipeline(vectorizer, classifier)\n",
    "\n",
    "maxent_pipeline.fit(training_corpus, training_labels) \n",
    "predicted_labels = maxent_pipeline.predict(test_corpus)\n",
    "get_metrics(true_labels=test_labels, predicted_labels=predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With **eli5**, you can get some insights into the most informative words in your corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: eli5 in /opt/conda/lib/python3.8/site-packages (0.11.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from eli5) (2.11.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /opt/conda/lib/python3.8/site-packages (from eli5) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from eli5) (1.19.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from eli5) (1.5.4)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.8/site-packages (from eli5) (0.8.9)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from eli5) (1.15.0)\n",
      "Requirement already satisfied: attrs>16.0.0 in /opt/conda/lib/python3.8/site-packages (from eli5) (20.2.0)\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.8/site-packages (from eli5) (0.16)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.8/site-packages (from jinja2->eli5) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.20->eli5) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.20->eli5) (0.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=pos\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.76%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.628\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        memorable\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.76%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 18553 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.58%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 17414 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.58%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.583\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        reason\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.50%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.588\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        script\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 83.94%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.618\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        awful\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 83.86%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.622\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        unfortunately\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 83.08%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.665\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        boring\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 82.19%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.716\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        waste\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 82.10%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.721\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        worst\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 81.49%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.757\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.845\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        bad\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "eli5.show_weights(classifier, vec=vectorizer, top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also explore your corpus and find out which specific tokens drove the classifier's decisions. Change the value of *item* to visualize what happened in each test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: neg; Groud truth: pos\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=neg\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.860</b>, score <b>-1.818</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.061\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.22%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.757\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 98.23%); opacity: 0.80\" title=\"-0.010\">airplane</span><span style=\"opacity: 0.80\"> ! is </span><span style=\"background-color: hsl(0, 100.00%, 91.83%); opacity: 0.82\" title=\"-0.087\">considered</span><span style=\"opacity: 0.80\"> among many to be the </span><span style=\"background-color: hsl(120, 100.00%, 95.83%); opacity: 0.81\" title=\"0.033\">epitome</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(0, 100.00%, 98.82%); opacity: 0.80\" title=\"-0.005\">satire</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.16%); opacity: 0.80\" title=\"-0.010\">film</span><span style=\"opacity: 0.80\"> - </span><span style=\"background-color: hsl(0, 100.00%, 97.79%); opacity: 0.80\" title=\"-0.013\">making</span><span style=\"opacity: 0.80\"> . after all , it &#x27; s </span><span style=\"background-color: hsl(0, 100.00%, 91.51%); opacity: 0.82\" title=\"-0.092\">brought</span><span style=\"opacity: 0.80\"> to us by one of the </span><span style=\"background-color: hsl(0, 100.00%, 76.22%); opacity: 0.90\" title=\"-0.402\">best</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.14%); opacity: 0.84\" title=\"-0.167\">known</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.82%); opacity: 0.80\" title=\"-0.005\">satire</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.43%); opacity: 0.81\" title=\"0.038\">writing</span><span style=\"opacity: 0.80\"> / </span><span style=\"background-color: hsl(0, 100.00%, 92.16%); opacity: 0.82\" title=\"-0.082\">directing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.81%); opacity: 0.80\" title=\"-0.013\">teams</span><span style=\"opacity: 0.80\"> . even if most </span><span style=\"background-color: hsl(0, 100.00%, 86.76%); opacity: 0.84\" title=\"-0.174\">people</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.25%); opacity: 0.80\" title=\"0.003\">don</span><span style=\"opacity: 0.80\"> &#x27; t </span><span style=\"background-color: hsl(120, 100.00%, 98.23%); opacity: 0.80\" title=\"0.010\">recognize</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(120, 100.00%, 89.65%); opacity: 0.83\" title=\"0.123\">names</span><span style=\"opacity: 0.80\"> behind the </span><span style=\"background-color: hsl(0, 100.00%, 97.29%); opacity: 0.80\" title=\"-0.018\">films</span><span style=\"opacity: 0.80\"> , they are </span><span style=\"background-color: hsl(0, 100.00%, 98.67%); opacity: 0.80\" title=\"-0.007\">bound</span><span style=\"opacity: 0.80\"> to </span><span style=\"background-color: hsl(120, 100.00%, 98.23%); opacity: 0.80\" title=\"0.010\">recognize</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(120, 100.00%, 96.41%); opacity: 0.81\" title=\"0.027\">titles</span><span style=\"opacity: 0.80\"> : </span><span style=\"background-color: hsl(0, 100.00%, 98.23%); opacity: 0.80\" title=\"-0.010\">airplane</span><span style=\"opacity: 0.80\"> ! , top </span><span style=\"background-color: hsl(0, 100.00%, 91.37%); opacity: 0.82\" title=\"-0.094\">secret</span><span style=\"opacity: 0.80\"> , the </span><span style=\"background-color: hsl(120, 100.00%, 78.38%); opacity: 0.88\" title=\"0.351\">naked</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.22%); opacity: 0.82\" title=\"0.097\">gun</span><span style=\"opacity: 0.80\"> , and </span><span style=\"background-color: hsl(0, 100.00%, 96.50%); opacity: 0.81\" title=\"-0.026\">hot</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.13%); opacity: 0.83\" title=\"0.114\">shots</span><span style=\"opacity: 0.80\"> to name a few . but although the </span><span style=\"background-color: hsl(0, 100.00%, 98.85%); opacity: 0.80\" title=\"-0.005\">zucker</span><span style=\"opacity: 0.80\"> / </span><span style=\"background-color: hsl(120, 100.00%, 94.22%); opacity: 0.81\" title=\"0.053\">abrahams</span><span style=\"opacity: 0.80\"> / </span><span style=\"background-color: hsl(0, 100.00%, 98.85%); opacity: 0.80\" title=\"-0.005\">zucker</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.99%); opacity: 0.81\" title=\"0.032\">team</span><span style=\"opacity: 0.80\"> was first </span><span style=\"background-color: hsl(0, 100.00%, 95.98%); opacity: 0.81\" title=\"-0.032\">introduced</span><span style=\"opacity: 0.80\"> with the </span><span style=\"background-color: hsl(0, 100.00%, 95.83%); opacity: 0.81\" title=\"-0.033\">kentucky</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.17%); opacity: 0.80\" title=\"-0.019\">fried</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.45%); opacity: 0.80\" title=\"-0.002\">movie</span><span style=\"opacity: 0.80\"> in </span><span style=\"background-color: hsl(0, 100.00%, 99.64%); opacity: 0.80\" title=\"-0.001\">1977</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(0, 100.00%, 98.23%); opacity: 0.80\" title=\"-0.010\">airplane</span><span style=\"opacity: 0.80\"> ! </span><span style=\"background-color: hsl(0, 100.00%, 89.08%); opacity: 0.83\" title=\"-0.132\">remains</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(0, 100.00%, 81.45%); opacity: 0.87\" title=\"-0.282\">true</span><span style=\"opacity: 0.80\"> cornerstone of their </span><span style=\"background-color: hsl(120, 100.00%, 85.70%); opacity: 0.85\" title=\"0.194\">work</span><span style=\"opacity: 0.80\"> , and their </span><span style=\"background-color: hsl(0, 100.00%, 98.07%); opacity: 0.80\" title=\"-0.011\">directorial</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.52%); opacity: 0.80\" title=\"-0.008\">debuts</span><span style=\"opacity: 0.80\"> . in the </span><span style=\"background-color: hsl(0, 100.00%, 96.02%); opacity: 0.81\" title=\"-0.031\">seventies</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(0, 100.00%, 98.91%); opacity: 0.80\" title=\"-0.005\">disaster</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.29%); opacity: 0.80\" title=\"-0.018\">films</span><span style=\"opacity: 0.80\"> seemed to be at an all </span><span style=\"background-color: hsl(0, 100.00%, 95.99%); opacity: 0.81\" title=\"-0.032\">time</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.52%); opacity: 0.81\" title=\"-0.049\">high</span><span style=\"opacity: 0.80\"> . </span><span style=\"background-color: hsl(0, 100.00%, 97.29%); opacity: 0.80\" title=\"-0.018\">films</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.87%); opacity: 0.83\" title=\"0.136\">like</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.06%); opacity: 0.81\" title=\"0.055\">earthquake</span><span style=\"opacity: 0.80\"> , the </span><span style=\"background-color: hsl(120, 100.00%, 93.43%); opacity: 0.82\" title=\"0.064\">towering</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.71%); opacity: 0.82\" title=\"0.074\">inferno</span><span style=\"opacity: 0.80\"> , and the </span><span style=\"background-color: hsl(0, 100.00%, 99.03%); opacity: 0.80\" title=\"-0.004\">poseidon</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.36%); opacity: 0.83\" title=\"-0.111\">adventure</span><span style=\"opacity: 0.80\"> were </span><span style=\"background-color: hsl(120, 100.00%, 93.09%); opacity: 0.82\" title=\"0.069\">big</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.87%); opacity: 0.83\" title=\"-0.119\">hits</span><span style=\"opacity: 0.80\"> . there was also a </span><span style=\"background-color: hsl(120, 100.00%, 91.23%); opacity: 0.82\" title=\"0.097\">series</span><span style=\"opacity: 0.80\"> about the </span><span style=\"background-color: hsl(0, 100.00%, 98.76%); opacity: 0.80\" title=\"-0.006\">disasters</span><span style=\"opacity: 0.80\"> that can </span><span style=\"background-color: hsl(120, 100.00%, 96.47%); opacity: 0.81\" title=\"0.026\">arise</span><span style=\"opacity: 0.80\"> when </span><span style=\"background-color: hsl(0, 100.00%, 88.26%); opacity: 0.83\" title=\"-0.147\">traveling</span><span style=\"opacity: 0.80\"> by </span><span style=\"background-color: hsl(120, 100.00%, 95.75%); opacity: 0.81\" title=\"0.034\">plane</span><span style=\"opacity: 0.80\"> - a </span><span style=\"background-color: hsl(120, 100.00%, 91.23%); opacity: 0.82\" title=\"0.097\">series</span><span style=\"opacity: 0.80\"> that </span><span style=\"background-color: hsl(120, 100.00%, 95.95%); opacity: 0.81\" title=\"0.032\">spanned</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(0, 100.00%, 92.13%); opacity: 0.82\" title=\"-0.083\">entire</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.42%); opacity: 0.82\" title=\"-0.094\">decade</span><span style=\"opacity: 0.80\"> . and so , in </span><span style=\"background-color: hsl(120, 100.00%, 94.49%); opacity: 0.81\" title=\"0.050\">1980</span><span style=\"opacity: 0.80\"> , we were </span><span style=\"background-color: hsl(0, 100.00%, 95.98%); opacity: 0.81\" title=\"-0.032\">introduced</span><span style=\"opacity: 0.80\"> to a </span><span style=\"background-color: hsl(0, 100.00%, 91.37%); opacity: 0.82\" title=\"-0.095\">new</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.23%); opacity: 0.80\" title=\"-0.010\">airplane</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.91%); opacity: 0.80\" title=\"-0.005\">disaster</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.16%); opacity: 0.80\" title=\"-0.010\">film</span><span style=\"opacity: 0.80\"> . this </span><span style=\"background-color: hsl(0, 100.00%, 95.99%); opacity: 0.81\" title=\"-0.032\">time</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(0, 100.00%, 98.91%); opacity: 0.80\" title=\"-0.005\">disaster</span><span style=\"opacity: 0.80\"> had nothing to do with a </span><span style=\"background-color: hsl(0, 100.00%, 96.39%); opacity: 0.81\" title=\"-0.027\">maniacal</span><span style=\"opacity: 0.80\"> hijacker or </span><span style=\"background-color: hsl(120, 100.00%, 93.62%); opacity: 0.81\" title=\"0.061\">crashing</span><span style=\"opacity: 0.80\"> into the </span><span style=\"background-color: hsl(120, 100.00%, 91.57%); opacity: 0.82\" title=\"0.091\">ocean</span><span style=\"opacity: 0.80\"> . . . it had to do with </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.845\">bad</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.87%); opacity: 0.80\" title=\"0.005\">fish</span><span style=\"opacity: 0.80\"> . </span><span style=\"background-color: hsl(0, 100.00%, 98.23%); opacity: 0.80\" title=\"-0.010\">airplane</span><span style=\"opacity: 0.80\"> ! is the </span><span style=\"background-color: hsl(120, 100.00%, 99.04%); opacity: 0.80\" title=\"0.004\">story</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(0, 100.00%, 97.54%); opacity: 0.80\" title=\"-0.016\">ted</span><span style=\"opacity: 0.80\"> striker ( </span><span style=\"background-color: hsl(120, 100.00%, 95.76%); opacity: 0.81\" title=\"0.034\">robert</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.33%); opacity: 0.80\" title=\"0.009\">hays</span><span style=\"opacity: 0.80\"> ) - an </span><span style=\"background-color: hsl(0, 100.00%, 92.50%); opacity: 0.82\" title=\"-0.077\">ex</span><span style=\"opacity: 0.80\"> - </span><span style=\"background-color: hsl(120, 100.00%, 89.23%); opacity: 0.83\" title=\"0.130\">fighter</span><span style=\"opacity: 0.80\"> - </span><span style=\"background-color: hsl(120, 100.00%, 94.68%); opacity: 0.81\" title=\"0.047\">pilot</span><span style=\"opacity: 0.80\"> who has never </span><span style=\"background-color: hsl(0, 100.00%, 94.40%); opacity: 0.81\" title=\"-0.051\">gotten</span><span style=\"opacity: 0.80\"> over the </span><span style=\"background-color: hsl(120, 100.00%, 95.05%); opacity: 0.81\" title=\"0.043\">fact</span><span style=\"opacity: 0.80\"> that a </span><span style=\"background-color: hsl(0, 100.00%, 95.23%); opacity: 0.81\" title=\"-0.041\">decision</span><span style=\"opacity: 0.80\"> he had to </span><span style=\"background-color: hsl(120, 100.00%, 78.00%); opacity: 0.89\" title=\"0.360\">make</span><span style=\"opacity: 0.80\"> in the </span><span style=\"background-color: hsl(120, 100.00%, 98.91%); opacity: 0.80\" title=\"0.005\">midst</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(0, 100.00%, 90.42%); opacity: 0.83\" title=\"-0.110\">war</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.89%); opacity: 0.83\" title=\"-0.119\">led</span><span style=\"opacity: 0.80\"> to the </span><span style=\"background-color: hsl(0, 100.00%, 94.38%); opacity: 0.81\" title=\"-0.051\">death</span><span style=\"opacity: 0.80\"> of six , </span><span style=\"background-color: hsl(120, 100.00%, 91.98%); opacity: 0.82\" title=\"0.085\">er</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(120, 100.00%, 92.63%); opacity: 0.82\" title=\"0.075\">seven</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.75%); opacity: 0.81\" title=\"0.047\">comrades</span><span style=\"opacity: 0.80\"> . </span><span style=\"background-color: hsl(120, 100.00%, 96.66%); opacity: 0.81\" title=\"0.024\">unable</span><span style=\"opacity: 0.80\"> to </span><span style=\"background-color: hsl(120, 100.00%, 94.87%); opacity: 0.81\" title=\"0.045\">stop</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.90%); opacity: 0.81\" title=\"-0.045\">living</span><span style=\"opacity: 0.80\"> in the </span><span style=\"background-color: hsl(120, 100.00%, 98.92%); opacity: 0.80\" title=\"0.005\">past</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(0, 100.00%, 97.54%); opacity: 0.80\" title=\"-0.016\">ted</span><span style=\"opacity: 0.80\"> &#x27; s </span><span style=\"background-color: hsl(0, 100.00%, 88.17%); opacity: 0.84\" title=\"-0.148\">world</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.48%); opacity: 0.80\" title=\"-0.002\">fell</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.62%); opacity: 0.81\" title=\"0.048\">apart</span><span style=\"opacity: 0.80\"> . he </span><span style=\"background-color: hsl(0, 100.00%, 94.55%); opacity: 0.81\" title=\"-0.049\">spent</span><span style=\"opacity: 0.80\"> his </span><span style=\"background-color: hsl(0, 100.00%, 95.99%); opacity: 0.81\" title=\"-0.032\">time</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.58%); opacity: 0.86\" title=\"-0.258\">moving</span><span style=\"opacity: 0.80\"> from </span><span style=\"background-color: hsl(120, 100.00%, 96.71%); opacity: 0.81\" title=\"0.024\">city</span><span style=\"opacity: 0.80\"> to </span><span style=\"background-color: hsl(120, 100.00%, 96.71%); opacity: 0.81\" title=\"0.024\">city</span><span style=\"opacity: 0.80\"> without ever </span><span style=\"background-color: hsl(120, 100.00%, 86.65%); opacity: 0.84\" title=\"0.176\">having</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(120, 100.00%, 97.31%); opacity: 0.80\" title=\"0.018\">stable</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.16%); opacity: 0.90\" title=\"-0.404\">job</span><span style=\"opacity: 0.80\"> , and </span><span style=\"background-color: hsl(0, 100.00%, 80.49%); opacity: 0.87\" title=\"-0.303\">eventually</span><span style=\"opacity: 0.80\"> , as we </span><span style=\"background-color: hsl(120, 100.00%, 88.79%); opacity: 0.83\" title=\"0.137\">begin</span><span style=\"opacity: 0.80\"> this </span><span style=\"background-color: hsl(0, 100.00%, 98.16%); opacity: 0.80\" title=\"-0.010\">film</span><span style=\"opacity: 0.80\"> , is </span><span style=\"background-color: hsl(0, 100.00%, 97.08%); opacity: 0.80\" title=\"-0.020\">getting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.85%); opacity: 0.81\" title=\"0.045\">dumped</span><span style=\"opacity: 0.80\"> by his </span><span style=\"background-color: hsl(120, 100.00%, 98.40%); opacity: 0.80\" title=\"0.008\">lover</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(120, 100.00%, 97.79%); opacity: 0.80\" title=\"0.014\">flight</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.64%); opacity: 0.80\" title=\"-0.001\">attendant</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.38%); opacity: 0.80\" title=\"-0.002\">elaine</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.54%); opacity: 0.80\" title=\"0.007\">dickinson</span><span style=\"opacity: 0.80\"> ( </span><span style=\"background-color: hsl(120, 100.00%, 85.56%); opacity: 0.85\" title=\"0.197\">julie</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.64%); opacity: 0.81\" title=\"0.025\">hagerty</span><span style=\"opacity: 0.80\"> ) . in a </span><span style=\"background-color: hsl(120, 100.00%, 96.13%); opacity: 0.81\" title=\"0.030\">desperate</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.97%); opacity: 0.90\" title=\"0.433\">attempt</span><span style=\"opacity: 0.80\"> not to </span><span style=\"background-color: hsl(120, 100.00%, 92.05%); opacity: 0.82\" title=\"0.084\">lose</span><span style=\"opacity: 0.80\"> her , </span><span style=\"background-color: hsl(0, 100.00%, 97.54%); opacity: 0.80\" title=\"-0.016\">ted</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.66%); opacity: 0.81\" title=\"0.035\">buys</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(0, 100.00%, 89.56%); opacity: 0.83\" title=\"-0.124\">ticket</span><span style=\"opacity: 0.80\"> for the same </span><span style=\"background-color: hsl(120, 100.00%, 97.79%); opacity: 0.80\" title=\"0.014\">flight</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.38%); opacity: 0.80\" title=\"-0.002\">elaine</span><span style=\"opacity: 0.80\"> is </span><span style=\"background-color: hsl(0, 100.00%, 93.71%); opacity: 0.81\" title=\"-0.060\">working</span><span style=\"opacity: 0.80\"> . </span><span style=\"background-color: hsl(120, 100.00%, 67.73%); opacity: 0.95\" title=\"0.622\">unfortunately</span><span style=\"opacity: 0.80\"> , she is </span><span style=\"background-color: hsl(120, 100.00%, 96.56%); opacity: 0.81\" title=\"0.025\">unsympathetic</span><span style=\"opacity: 0.80\"> and even </span><span style=\"background-color: hsl(120, 100.00%, 96.46%); opacity: 0.81\" title=\"0.026\">criticizes</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.54%); opacity: 0.80\" title=\"-0.016\">ted</span><span style=\"opacity: 0.80\"> for </span><span style=\"background-color: hsl(120, 100.00%, 94.96%); opacity: 0.81\" title=\"0.044\">following</span><span style=\"opacity: 0.80\"> her , which </span><span style=\"background-color: hsl(120, 100.00%, 89.00%); opacity: 0.83\" title=\"0.134\">leaves</span><span style=\"opacity: 0.80\"> him </span><span style=\"background-color: hsl(120, 100.00%, 99.37%); opacity: 0.80\" title=\"0.002\">wallowing</span><span style=\"opacity: 0.80\"> in </span><span style=\"background-color: hsl(120, 100.00%, 90.67%); opacity: 0.83\" title=\"0.106\">self</span><span style=\"opacity: 0.80\"> - </span><span style=\"background-color: hsl(0, 100.00%, 93.74%); opacity: 0.81\" title=\"-0.060\">pity</span><span style=\"opacity: 0.80\"> . in the </span><span style=\"background-color: hsl(120, 100.00%, 98.91%); opacity: 0.80\" title=\"0.005\">midst</span><span style=\"opacity: 0.80\"> of it all , something </span><span style=\"background-color: hsl(120, 100.00%, 86.94%); opacity: 0.84\" title=\"0.171\">happens</span><span style=\"opacity: 0.80\"> . someone </span><span style=\"background-color: hsl(120, 100.00%, 87.40%); opacity: 0.84\" title=\"0.162\">gets</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.62%); opacity: 0.81\" title=\"-0.061\">sick</span><span style=\"opacity: 0.80\"> . then another . then another . </span><span style=\"background-color: hsl(0, 100.00%, 95.21%); opacity: 0.81\" title=\"-0.041\">soon</span><span style=\"opacity: 0.80\"> , the whole </span><span style=\"background-color: hsl(120, 100.00%, 95.75%); opacity: 0.81\" title=\"0.034\">plane</span><span style=\"opacity: 0.80\"> is full of deathly - </span><span style=\"background-color: hsl(120, 100.00%, 84.76%); opacity: 0.85\" title=\"0.213\">ill</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.89%); opacity: 0.83\" title=\"-0.118\">chicago</span><span style=\"opacity: 0.80\"> - </span><span style=\"background-color: hsl(0, 100.00%, 98.67%); opacity: 0.80\" title=\"-0.007\">bound</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.76%); opacity: 0.84\" title=\"-0.174\">people</span><span style=\"opacity: 0.80\"> . . . and when the </span><span style=\"background-color: hsl(120, 100.00%, 95.01%); opacity: 0.81\" title=\"0.043\">pilots</span><span style=\"opacity: 0.80\"> get </span><span style=\"background-color: hsl(0, 100.00%, 93.62%); opacity: 0.81\" title=\"-0.061\">sick</span><span style=\"opacity: 0.80\"> ( </span><span style=\"background-color: hsl(120, 100.00%, 97.21%); opacity: 0.80\" title=\"0.019\">played</span><span style=\"opacity: 0.80\"> by </span><span style=\"background-color: hsl(120, 100.00%, 98.53%); opacity: 0.80\" title=\"0.008\">peter</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.28%); opacity: 0.80\" title=\"0.018\">graves</span><span style=\"opacity: 0.80\"> , kareem abdul - jabbar , and </span><span style=\"background-color: hsl(0, 100.00%, 78.66%); opacity: 0.88\" title=\"-0.345\">frank</span><span style=\"opacity: 0.80\"> ashmore ) , who will </span><span style=\"background-color: hsl(120, 100.00%, 76.92%); opacity: 0.89\" title=\"0.385\">save</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(0, 100.00%, 85.97%); opacity: 0.84\" title=\"-0.189\">day</span><span style=\"opacity: 0.80\"> ? ( </span><span style=\"background-color: hsl(120, 100.00%, 91.10%); opacity: 0.82\" title=\"0.099\">gee</span><span style=\"opacity: 0.80\"> , i </span><span style=\"background-color: hsl(120, 100.00%, 80.00%); opacity: 0.87\" title=\"0.314\">wonder</span><span style=\"opacity: 0.80\"> ) of </span><span style=\"background-color: hsl(0, 100.00%, 93.11%); opacity: 0.82\" title=\"-0.069\">course</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(120, 100.00%, 84.62%); opacity: 0.85\" title=\"0.216\">main</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.46%); opacity: 0.80\" title=\"0.016\">draw</span><span style=\"opacity: 0.80\"> here is the </span><span style=\"background-color: hsl(0, 100.00%, 89.23%); opacity: 0.83\" title=\"-0.130\">non</span><span style=\"opacity: 0.80\"> - </span><span style=\"background-color: hsl(120, 100.00%, 94.87%); opacity: 0.81\" title=\"0.045\">stop</span><span style=\"opacity: 0.80\"> &quot; </span><span style=\"background-color: hsl(0, 100.00%, 97.53%); opacity: 0.80\" title=\"-0.016\">whiz</span><span style=\"opacity: 0.80\"> - </span><span style=\"background-color: hsl(120, 100.00%, 95.03%); opacity: 0.81\" title=\"0.043\">bang</span><span style=\"opacity: 0.80\"> &quot; </span><span style=\"background-color: hsl(120, 100.00%, 84.49%); opacity: 0.85\" title=\"0.218\">comedy</span><span style=\"opacity: 0.80\"> , with a </span><span style=\"background-color: hsl(0, 100.00%, 95.25%); opacity: 0.81\" title=\"-0.040\">hefty</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.18%); opacity: 0.80\" title=\"0.019\">dose</span><span style=\"opacity: 0.80\"> of both </span><span style=\"background-color: hsl(0, 100.00%, 86.02%); opacity: 0.84\" title=\"-0.188\">visual</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(0, 100.00%, 91.79%); opacity: 0.82\" title=\"-0.088\">spoken</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.98%); opacity: 0.82\" title=\"0.101\">gags</span><span style=\"opacity: 0.80\"> . although i had </span><span style=\"background-color: hsl(0, 100.00%, 90.88%); opacity: 0.82\" title=\"-0.102\">seen</span><span style=\"opacity: 0.80\"> this </span><span style=\"background-color: hsl(0, 100.00%, 99.45%); opacity: 0.80\" title=\"-0.002\">movie</span><span style=\"opacity: 0.80\"> a few </span><span style=\"background-color: hsl(0, 100.00%, 94.02%); opacity: 0.81\" title=\"-0.056\">times</span><span style=\"opacity: 0.80\"> before , i was still </span><span style=\"background-color: hsl(0, 100.00%, 88.20%); opacity: 0.83\" title=\"-0.148\">laughing</span><span style=\"opacity: 0.80\"> thru the </span><span style=\"background-color: hsl(0, 100.00%, 92.13%); opacity: 0.82\" title=\"-0.083\">entire</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.33%); opacity: 0.81\" title=\"0.028\">thing</span><span style=\"opacity: 0.80\"> . the most </span><span style=\"background-color: hsl(0, 100.00%, 72.06%); opacity: 0.92\" title=\"-0.506\">fun</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.94%); opacity: 0.82\" title=\"0.086\">character</span><span style=\"opacity: 0.80\"> by </span><span style=\"background-color: hsl(120, 100.00%, 91.98%); opacity: 0.82\" title=\"0.085\">far</span><span style=\"opacity: 0.80\"> is the </span><span style=\"background-color: hsl(120, 100.00%, 90.37%); opacity: 0.83\" title=\"0.111\">doctor</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(120, 100.00%, 97.21%); opacity: 0.80\" title=\"0.019\">played</span><span style=\"opacity: 0.80\"> by </span><span style=\"background-color: hsl(120, 100.00%, 92.86%); opacity: 0.82\" title=\"0.072\">leslie</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.75%); opacity: 0.82\" title=\"0.089\">nielsen</span><span style=\"opacity: 0.80\"> . he &#x27; s a </span><span style=\"background-color: hsl(120, 100.00%, 93.77%); opacity: 0.81\" title=\"0.059\">dry</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(0, 100.00%, 88.94%); opacity: 0.83\" title=\"-0.135\">subtle</span><span style=\"opacity: 0.80\"> , sterotypically </span><span style=\"background-color: hsl(120, 100.00%, 88.43%); opacity: 0.83\" title=\"0.144\">straight</span><span style=\"opacity: 0.80\"> - </span><span style=\"background-color: hsl(0, 100.00%, 87.75%); opacity: 0.84\" title=\"-0.156\">faced</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.37%); opacity: 0.83\" title=\"0.111\">doctor</span><span style=\"opacity: 0.80\"> that </span><span style=\"background-color: hsl(120, 100.00%, 80.18%); opacity: 0.87\" title=\"0.310\">ends</span><span style=\"opacity: 0.80\"> up </span><span style=\"background-color: hsl(0, 100.00%, 96.27%); opacity: 0.81\" title=\"-0.028\">saying</span><span style=\"opacity: 0.80\"> some of the </span><span style=\"background-color: hsl(0, 100.00%, 95.37%); opacity: 0.81\" title=\"-0.039\">funniest</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.66%); opacity: 0.80\" title=\"-0.007\">lines</span><span style=\"opacity: 0.80\"> of the </span><span style=\"background-color: hsl(0, 100.00%, 98.16%); opacity: 0.80\" title=\"-0.010\">film</span><span style=\"opacity: 0.80\"> . in a </span><span style=\"background-color: hsl(0, 100.00%, 98.16%); opacity: 0.80\" title=\"-0.010\">film</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.87%); opacity: 0.83\" title=\"0.136\">like</span><span style=\"opacity: 0.80\"> this , you &#x27; re not </span><span style=\"background-color: hsl(0, 100.00%, 95.92%); opacity: 0.81\" title=\"-0.032\">really</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.47%); opacity: 0.83\" title=\"-0.109\">expecting</span><span style=\"opacity: 0.80\"> an </span><span style=\"background-color: hsl(120, 100.00%, 91.36%); opacity: 0.82\" title=\"0.095\">elaborate</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.83%); opacity: 0.84\" title=\"-0.173\">production</span><span style=\"opacity: 0.80\"> , so one can &#x27; t </span><span style=\"background-color: hsl(120, 100.00%, 98.44%); opacity: 0.80\" title=\"0.008\">complain</span><span style=\"opacity: 0.80\"> about the </span><span style=\"background-color: hsl(120, 100.00%, 91.33%); opacity: 0.82\" title=\"0.095\">amateurish</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.68%); opacity: 0.82\" title=\"0.090\">quality</span><span style=\"opacity: 0.80\"> . what you can </span><span style=\"background-color: hsl(120, 100.00%, 98.44%); opacity: 0.80\" title=\"0.008\">complain</span><span style=\"opacity: 0.80\"> about is the </span><span style=\"background-color: hsl(0, 100.00%, 97.78%); opacity: 0.80\" title=\"-0.014\">absolutely</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.56%); opacity: 0.88\" title=\"0.347\">annoying</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.00%); opacity: 0.80\" title=\"-0.021\">johnny</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(120, 100.00%, 97.21%); opacity: 0.80\" title=\"0.019\">played</span><span style=\"opacity: 0.80\"> by </span><span style=\"background-color: hsl(0, 100.00%, 86.77%); opacity: 0.84\" title=\"-0.174\">stephen</span><span style=\"opacity: 0.80\"> stucker . this </span><span style=\"background-color: hsl(120, 100.00%, 91.94%); opacity: 0.82\" title=\"0.086\">character</span><span style=\"opacity: 0.80\"> is </span><span style=\"background-color: hsl(120, 100.00%, 77.09%); opacity: 0.89\" title=\"0.381\">pointless</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(120, 100.00%, 96.26%); opacity: 0.81\" title=\"0.029\">nauseating</span><span style=\"opacity: 0.80\"> , and very </span><span style=\"background-color: hsl(120, 100.00%, 82.53%); opacity: 0.86\" title=\"0.259\">unfunny</span><span style=\"opacity: 0.80\"> . i </span><span style=\"background-color: hsl(120, 100.00%, 99.25%); opacity: 0.80\" title=\"0.003\">don</span><span style=\"opacity: 0.80\"> &#x27; t </span><span style=\"background-color: hsl(120, 100.00%, 93.80%); opacity: 0.81\" title=\"0.059\">know</span><span style=\"opacity: 0.80\"> why he was put in there , and i </span><span style=\"background-color: hsl(120, 100.00%, 99.25%); opacity: 0.80\" title=\"0.003\">don</span><span style=\"opacity: 0.80\"> &#x27; t </span><span style=\"background-color: hsl(0, 100.00%, 89.80%); opacity: 0.83\" title=\"-0.120\">think</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.51%); opacity: 0.80\" title=\"0.008\">anybody</span><span style=\"opacity: 0.80\"> will find a </span><span style=\"background-color: hsl(0, 100.00%, 92.77%); opacity: 0.82\" title=\"-0.073\">good</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.89%); opacity: 0.86\" title=\"0.251\">excuse</span><span style=\"opacity: 0.80\"> . and when the </span><span style=\"background-color: hsl(0, 100.00%, 98.16%); opacity: 0.80\" title=\"-0.010\">film</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.13%); opacity: 0.80\" title=\"0.011\">nears</span><span style=\"opacity: 0.80\"> an </span><span style=\"background-color: hsl(120, 100.00%, 90.53%); opacity: 0.83\" title=\"0.108\">end</span><span style=\"opacity: 0.80\"> , it </span><span style=\"background-color: hsl(0, 100.00%, 96.75%); opacity: 0.81\" title=\"-0.023\">slows</span><span style=\"opacity: 0.80\"> down </span><span style=\"background-color: hsl(0, 100.00%, 80.14%); opacity: 0.87\" title=\"-0.311\">quite</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(0, 100.00%, 90.02%); opacity: 0.83\" title=\"-0.116\">bit</span><span style=\"opacity: 0.80\"> , almost </span><span style=\"background-color: hsl(0, 100.00%, 97.08%); opacity: 0.80\" title=\"-0.020\">getting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.41%); opacity: 0.83\" title=\"0.127\">old</span><span style=\"opacity: 0.80\"> . you </span><span style=\"background-color: hsl(120, 100.00%, 94.64%); opacity: 0.81\" title=\"0.048\">gotta</span><span style=\"opacity: 0.80\"> give it to a </span><span style=\"background-color: hsl(0, 100.00%, 99.45%); opacity: 0.80\" title=\"-0.002\">movie</span><span style=\"opacity: 0.80\"> that only </span><span style=\"background-color: hsl(0, 100.00%, 90.74%); opacity: 0.82\" title=\"-0.104\">runs</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.84%); opacity: 0.80\" title=\"-0.013\">88</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.64%); opacity: 0.88\" title=\"0.345\">minutes</span><span style=\"opacity: 0.80\"> and can </span><span style=\"background-color: hsl(120, 100.00%, 97.44%); opacity: 0.80\" title=\"0.017\">feel</span><span style=\"opacity: 0.80\"> two </span><span style=\"background-color: hsl(0, 100.00%, 98.78%); opacity: 0.80\" title=\"-0.006\">hours</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.58%); opacity: 0.83\" title=\"0.141\">long</span><span style=\"opacity: 0.80\"> . </span><span style=\"background-color: hsl(0, 100.00%, 97.25%); opacity: 0.80\" title=\"-0.018\">aside</span><span style=\"opacity: 0.80\"> from that , </span><span style=\"background-color: hsl(0, 100.00%, 98.23%); opacity: 0.80\" title=\"-0.010\">airplane</span><span style=\"opacity: 0.80\"> ! is </span><span style=\"background-color: hsl(0, 100.00%, 95.92%); opacity: 0.81\" title=\"-0.032\">really</span><span style=\"opacity: 0.80\"> a top - </span><span style=\"background-color: hsl(0, 100.00%, 83.45%); opacity: 0.86\" title=\"-0.239\">notch</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.89%); opacity: 0.81\" title=\"0.045\">spoof</span><span style=\"opacity: 0.80\"> that will </span><span style=\"background-color: hsl(120, 100.00%, 91.17%); opacity: 0.82\" title=\"0.098\">likely</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.36%); opacity: 0.81\" title=\"0.028\">forever</span><span style=\"opacity: 0.80\"> be </span><span style=\"background-color: hsl(0, 100.00%, 87.14%); opacity: 0.84\" title=\"-0.167\">known</span><span style=\"opacity: 0.80\"> as a </span><span style=\"background-color: hsl(120, 100.00%, 94.89%); opacity: 0.81\" title=\"0.045\">spoof</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.53%); opacity: 0.83\" title=\"-0.108\">classic</span><span style=\"opacity: 0.80\"> . it would be a </span><span style=\"background-color: hsl(0, 100.00%, 92.77%); opacity: 0.82\" title=\"-0.073\">good</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.12%); opacity: 0.84\" title=\"-0.186\">choice</span><span style=\"opacity: 0.80\"> to </span><span style=\"background-color: hsl(0, 100.00%, 92.99%); opacity: 0.82\" title=\"-0.070\">pop</span><span style=\"opacity: 0.80\"> in the </span><span style=\"background-color: hsl(0, 100.00%, 98.84%); opacity: 0.80\" title=\"-0.005\">vcr</span><span style=\"opacity: 0.80\"> with a </span><span style=\"background-color: hsl(0, 100.00%, 95.86%); opacity: 0.81\" title=\"-0.033\">group</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(0, 100.00%, 80.37%); opacity: 0.87\" title=\"-0.306\">friends</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(0, 100.00%, 75.65%); opacity: 0.90\" title=\"-0.416\">especially</span><span style=\"opacity: 0.80\"> if they </span><span style=\"background-color: hsl(120, 100.00%, 99.24%); opacity: 0.80\" title=\"0.003\">haven</span><span style=\"opacity: 0.80\"> &#x27; t </span><span style=\"background-color: hsl(0, 100.00%, 90.88%); opacity: 0.82\" title=\"-0.102\">seen</span><span style=\"opacity: 0.80\"> it . and if they </span><span style=\"background-color: hsl(120, 100.00%, 96.49%); opacity: 0.81\" title=\"0.026\">ask</span><span style=\"opacity: 0.80\"> what the </span><span style=\"background-color: hsl(120, 100.00%, 70.30%); opacity: 0.93\" title=\"0.553\">plot</span><span style=\"opacity: 0.80\"> is , </span><span style=\"background-color: hsl(0, 100.00%, 98.55%); opacity: 0.80\" title=\"-0.007\">just</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.49%); opacity: 0.85\" title=\"-0.198\">tell</span><span style=\"opacity: 0.80\"> &#x27; </span><span style=\"background-color: hsl(0, 100.00%, 97.48%); opacity: 0.80\" title=\"-0.016\">em</span><span style=\"opacity: 0.80\"> &quot; it &#x27; s a </span><span style=\"background-color: hsl(0, 100.00%, 93.53%); opacity: 0.81\" title=\"-0.063\">synopsis</span><span style=\"opacity: 0.80\"> of the </span><span style=\"background-color: hsl(0, 100.00%, 93.33%); opacity: 0.82\" title=\"-0.065\">basic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.18%); opacity: 0.82\" title=\"0.097\">storyline</span><span style=\"opacity: 0.80\"> of the </span><span style=\"background-color: hsl(0, 100.00%, 98.16%); opacity: 0.80\" title=\"-0.010\">film</span><span style=\"opacity: 0.80\"> , but that &#x27; s not </span><span style=\"background-color: hsl(0, 100.00%, 88.98%); opacity: 0.83\" title=\"-0.134\">important</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.49%); opacity: 0.88\" title=\"-0.349\">right</span><span style=\"opacity: 0.80\"> now . &quot; if you &#x27; </span><span style=\"background-color: hsl(0, 100.00%, 87.09%); opacity: 0.84\" title=\"-0.168\">ve</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.88%); opacity: 0.82\" title=\"-0.102\">seen</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(0, 100.00%, 98.16%); opacity: 0.80\" title=\"-0.010\">film</span><span style=\"opacity: 0.80\"> , you &#x27; </span><span style=\"background-color: hsl(0, 100.00%, 86.90%); opacity: 0.84\" title=\"-0.172\">ll</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.23%); opacity: 0.84\" title=\"0.165\">understand</span><span style=\"opacity: 0.80\"> ; - )</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = 16\n",
    "print ('Prediction: ' + predicted_labels[item] + '; Groud truth: ' + test_labels[item])\n",
    "eli5.show_prediction(classifier, test_corpus[item], vec=vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've made it this far, you will have seen that the decisions are affected by words that are supposed to have a neutral semantic orientation. Open question: can you provide a few examples of such words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems reasonable to get the classifier to focus on sentiment words. Let's begin by extracting a list of positive words and a list of negative words as we did in Lab 3b. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Words/positive-words.txt', errors='ignore') as opened:\n",
    "    contents = opened.read()\n",
    "contents_lines = ['a+'] + contents.split('a+')[1].split('\\n')\n",
    "positive_words = [x for x in contents_lines if len(x)>0]\n",
    "\n",
    "with open('Words/negative-words.txt', errors='ignore') as opened:\n",
    "    contents = opened.read()\n",
    "contents_lines = ['2-faced'] + contents.split('2-faced')[1].split('\\n')\n",
    "negative_words = [x for x in contents_lines if len(x)>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's write a function to remove non-sentiment tokens from our corpus. Once we have it, we'll run it on the training corpus and the test corpus to transform them into sentiment-only corpora. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def remove_non_sentiment_tokens(corpus):\n",
    "    sentiment_only_corpus=[]\n",
    "    for document in corpus:\n",
    "        document_words = set(word for word in word_tokenize(document))\n",
    "        sentiment_words = list(document_words.intersection(positive_words))+\\\n",
    "                          list(document_words.intersection(negative_words))\n",
    "        sentiment_only_corpus.append(' '.join(sentiment_words))\n",
    "        \n",
    "    return sentiment_only_corpus   \n",
    "    \n",
    "sentiment_only_training_corpus = remove_non_sentiment_tokens(training_corpus)\n",
    "sentiment_only_test_corpus = remove_non_sentiment_tokens(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, please train **maxent_pipeline** on the **sentiment_only_training_corpus** and test it on the **sentiment_only_test_corpus**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.835\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.81      0.83       198\n",
      "         pos       0.82      0.86      0.84       202\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.83       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxent_pipeline.fit(sentiment_only_training_corpus, training_labels) \n",
    "predicted_labels = maxent_pipeline.predict(sentiment_only_test_corpus)\n",
    "get_metrics(true_labels=test_labels, predicted_labels=predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open question: what do you think about the performance improvement? Is it greater than you expected, smaller than you expected, or just about what you expected? Why? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
