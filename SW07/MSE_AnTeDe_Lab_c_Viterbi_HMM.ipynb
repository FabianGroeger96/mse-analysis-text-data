{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnTeDe Lab C: Viterbi Algorithm for HMM\n",
    "\n",
    "## Session goal\n",
    "The goal of this session is reproduce the example in Chapter 8 of **Speech and Language Processing** by Daniel Jurafsky & James H. Martin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hardcode the same data used in the example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentence = 'Janet will back the bill'\n",
    "import nltk.tokenize as tokenize        \n",
    "observations = ('Janet', 'will', 'back', 'the', 'bill')\n",
    "observations = tokenize.word_tokenize(sentence)\n",
    "\n",
    "states = ('NNP', 'MD', 'VB', 'JJ', 'NN', 'RB', 'DT')\n",
    "starting_p_values = [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026]\n",
    "\n",
    "starting_p = {}\n",
    "\n",
    "for i, key in enumerate(states):\n",
    "    starting_p[key]=starting_p_values[i]\n",
    "    \n",
    "valid_transitions={}\n",
    "    \n",
    "valid_transitions['NNP']=[0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025]\n",
    "valid_transitions['MD']=[0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041]\n",
    "valid_transitions['VB']=[0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231]\n",
    "valid_transitions['JJ']=[0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036]\n",
    "valid_transitions['NN']=[0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068]\n",
    "valid_transitions['RB']=[0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479]\n",
    "valid_transitions['DT']=[0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017]\n",
    "\n",
    "transition_p = {}\n",
    "\n",
    "for key in valid_transitions:\n",
    "    transition_p[key] = {}\n",
    "    for i, state in enumerate(states):\n",
    "        transition_p[key][state]= valid_transitions[key][i]\n",
    "        \n",
    "            \n",
    "valid_emissions={}          \n",
    "valid_emissions['NNP']={'Janet': 0.000032, 'the': 0.000048,}  \n",
    "valid_emissions['MD']={'will': 0.308431,}       \n",
    "valid_emissions['VB']={'will': 0.000028, 'back': 0.000672, 'bill': 0.000028,}     \n",
    "valid_emissions['JJ']={'back': 0.000340,} \n",
    "valid_emissions['NN']={'will': 0.000200, 'back': 0.000223, 'bill': 0.002337,}     \n",
    "valid_emissions['RB']={'back': 0.010446,}  \n",
    "valid_emissions['DT']={'the': 0.506099,}  \n",
    "emission_p = {}\n",
    "\n",
    "for key in valid_emissions:\n",
    "    emission_p[key] = {}\n",
    "    for word in observations:\n",
    "        try:\n",
    "            emission_p[key][word]= valid_emissions[key][word]\n",
    "        except:\n",
    "            emission_p[key][word]= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains an implementation of a Viterbi decoder for  an HMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(observations, states, starting_p, transition_p, emission_p):\n",
    "    \n",
    "    # your trellis is a list of dictionaries\n",
    "    trellis = [{}]\n",
    "\n",
    "    # first column of the trellis: \n",
    "    # how likely you are to start in each state, multiplied by \n",
    "    # how likely you are to generate the initial observation \n",
    "    # from each state\n",
    "    for state in states:\n",
    "        trellis[0][state] = \\\n",
    "        {\"probability\":\\\n",
    "         starting_p[state] * emission_p[state][observations[0]],\\\n",
    "               \"previous state\": None}\n",
    "\n",
    "    # for loop over the trellis columns, left to right\n",
    "    for k in range(1, len(observations)):\n",
    "\n",
    "        # add a column\n",
    "        new_column = {}\n",
    "\n",
    "        # for each row in the column\n",
    "        for state in states:\n",
    "            \n",
    "            max_path_p=0\n",
    "\n",
    "            for previous_state in states:\n",
    "\n",
    "                up_to_here_p =\\\n",
    "                    trellis[k-1][previous_state][\"probability\"]*\\\n",
    "                    transition_p[previous_state][state]\n",
    "\n",
    "                if up_to_here_p > max_path_p:\n",
    "\n",
    "                    max_path_p = up_to_here_p\n",
    "\n",
    "                    prev_st_selected = previous_state\n",
    "\n",
    "                    \n",
    "\n",
    "            max_p = max_path_p * emission_p[state][observations[k]]\n",
    "\n",
    "            \n",
    "            \n",
    "            new_column[state]=\\\n",
    "            {\"probability\": max_p,\\\n",
    "             \"previous\": prev_st_selected}\n",
    "            \n",
    "        trellis.append(new_column)\n",
    "\n",
    "    max_prob = max(value[\"probability\"]\\\n",
    "                   for value in trellis[-1].values())\n",
    "\n",
    "    previous = None\n",
    "\n",
    "    return trellis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your turn: run **viterbi** and obtain the trellis for our HMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Janet\n",
      "{'NNP': {'probability': 8.8544e-06, 'previous state': None}, 'MD': {'probability': 0.0, 'previous state': None}, 'VB': {'probability': 0.0, 'previous state': None}, 'JJ': {'probability': 0.0, 'previous state': None}, 'NN': {'probability': 0.0, 'previous state': None}, 'RB': {'probability': 0.0, 'previous state': None}, 'DT': {'probability': 0.0, 'previous state': None}}\n",
      "will\n",
      "{'NNP': {'probability': 0.0, 'previous': 'NNP'}, 'MD': {'probability': 3.00406859104e-08, 'previous': 'NNP'}, 'VB': {'probability': 2.2313087999999997e-13, 'previous': 'NNP'}, 'JJ': {'probability': 0.0, 'previous': 'NNP'}, 'NN': {'probability': 1.03419392e-10, 'previous': 'NNP'}, 'RB': {'probability': 0.0, 'previous': 'NNP'}, 'DT': {'probability': 0.0, 'previous': 'NNP'}}\n",
      "back\n",
      "{'NNP': {'probability': 0.0, 'previous': 'MD'}, 'MD': {'probability': 0.0, 'previous': 'MD'}, 'VB': {'probability': 1.6085273254449314e-11, 'previous': 'MD'}, 'JJ': {'probability': 5.106916604768e-15, 'previous': 'MD'}, 'NN': {'probability': 5.35925836641536e-15, 'previous': 'MD'}, 'RB': {'probability': 5.3284089852402517e-11, 'previous': 'MD'}, 'DT': {'probability': 0.0, 'previous': 'MD'}}\n",
      "the\n",
      "{'NNP': {'probability': 2.486139834207686e-17, 'previous': 'VB'}, 'MD': {'probability': 0.0, 'previous': 'RB'}, 'VB': {'probability': 0.0, 'previous': 'RB'}, 'JJ': {'probability': 0.0, 'previous': 'RB'}, 'NN': {'probability': 0.0, 'previous': 'VB'}, 'RB': {'probability': 0.0, 'previous': 'RB'}, 'DT': {'probability': 1.8161992521340703e-12, 'previous': 'VB'}}\n",
      "bill\n",
      "{'NNP': {'probability': 0.0, 'previous': 'DT'}, 'MD': {'probability': 0.0, 'previous': 'DT'}, 'VB': {'probability': 1.0170715811950793e-20, 'previous': 'DT'}, 'JJ': {'probability': 0.0, 'previous': 'DT'}, 'NN': {'probability': 2.013570710221386e-15, 'previous': 'DT'}, 'RB': {'probability': 0.0, 'previous': 'DT'}, 'DT': {'probability': 0.0, 'previous': 'DT'}}\n"
     ]
    }
   ],
   "source": [
    "my_trellis=[{}]\n",
    "# BEGIN_REMOVE\n",
    "my_trellis=viterbi(observations, states, starting_p, transition_p, emission_p)\n",
    "# END_REMOVE\n",
    "for i, column in enumerate(my_trellis):\n",
    "    print (observations[i])\n",
    "    print (column)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your turn: write a function **get_pos_tag_sequence** that accepts the Viterbi-decoded trellis as input and prints out the tag for each word in the test sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_tag_sequence (trellis):\n",
    "# BEGIN_REMOVE\n",
    "    import numpy as np\n",
    "    probs=[trellis[-1][state]['probability'] for state in trellis[-1].keys()]\n",
    "    chosen=np.max(np.asarray(probs))\n",
    "    chosen_state=[(state, trellis[-1][state]['previous'])\\\n",
    "                  for state in trellis[-1].keys() if trellis[-1][state]['probability']==chosen]\n",
    "\n",
    "    opt=[chosen_state[0][0]]\n",
    "    previous=chosen_state[0][1]\n",
    "\n",
    "    for t in range(len(trellis) - 2, -1, -1):\n",
    "        opt.insert(0, trellis[t + 1][previous][\"previous\"])\n",
    "        previous = trellis[t + 1][previous][\"previous\"]\n",
    "\n",
    "    for i, word in enumerate(observations):\n",
    "        print (word+'\\t'+opt[i])\n",
    "# END_REMOVE        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Janet\tNNP\n",
      "will\tMD\n",
      "back\tVB\n",
      "the\tDT\n",
      "bill\tNN\n"
     ]
    }
   ],
   "source": [
    "get_pos_tag_sequence(my_trellis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
