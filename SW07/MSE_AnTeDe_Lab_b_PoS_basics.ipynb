{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnTeDe Lab B: using PoS taggers \n",
    "\n",
    "## Session goal\n",
    "\n",
    "The goal of this session is to help you familiarize with PoS tagging. We'll be using NLTK, Stanza, and Spacy.\n",
    "For Spacy, in addition to *pip install spacy*, you'll need to run *python -m spacy download en_core_web_sm*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-07 17:33:13 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2021-04-07 17:33:13 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| pos       | ewt     |\n",
      "| lemma     | ewt     |\n",
      "=======================\n",
      "\n",
      "2021-04-07 17:33:13 INFO: Use device: cpu\n",
      "2021-04-07 17:33:13 INFO: Loading: tokenize\n",
      "2021-04-07 17:33:13 INFO: Loading: pos\n",
      "2021-04-07 17:33:14 INFO: Loading: lemma\n",
      "2021-04-07 17:33:14 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "\n",
    "from nltk.tag import PerceptronTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import spacy\n",
    "\n",
    "\n",
    "text='I really like this class. This lab is going to be fun.'\n",
    "\n",
    "stanza_pipeline = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma')\n",
    "spacy_analyzer = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def run_stanza(text):\n",
    "    \n",
    "    pairs=[]    \n",
    "    doc = stanza_pipeline(text)\n",
    "    for sent in doc.sentences:\n",
    "        for word in sent.words:\n",
    "            pairs.append((word.text, word.xpos))\n",
    "    return pairs        \n",
    "\n",
    "def run_spacy(text):\n",
    "    \n",
    "    doc = spacy_analyzer(text)\n",
    "    return [(token, token.tag_) for token in doc]\n",
    "\n",
    "def run_nltk (text):\n",
    "    \n",
    "    tagger = PerceptronTagger()\n",
    "    return tagger.tag(word_tokenize(text))\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pos_results (text):\n",
    "    \n",
    "    stanza_pairs = run_stanza(text)    \n",
    "    spacy_pairs = run_spacy(text)   \n",
    "    nltk_pairs = run_nltk(text) \n",
    "\n",
    "    if len(stanza_pairs)==len(spacy_pairs)==len(nltk_pairs):\n",
    "        tokens = [x[0] for x in stanza_pairs]\n",
    "        stanza_tags = [x[1] for x in stanza_pairs]\n",
    "        spacy_tags = [x[1] for x in spacy_pairs]\n",
    "        nltk_tags = [x[1] for x in nltk_pairs]\n",
    "\n",
    "        import pandas as pd    \n",
    "        df=pd.DataFrame(columns = ['tokens','Stanza', 'NLTK', 'Spacy'])   \n",
    "        df['tokens']=tokens\n",
    "        df['Stanza']=stanza_tags\n",
    "        df['NLTK']=nltk_tags\n",
    "        df['Spacy']=spacy_tags\n",
    "\n",
    "        print (df)\n",
    "\n",
    "    else:\n",
    "        print ('-'*30)\n",
    "        print ('Stanza')\n",
    "        print (stanza_pairs)\n",
    "        print ('-'*30)\n",
    "        print ('NLTK')\n",
    "        print (nltk_pairs)\n",
    "        print ('-'*30)\n",
    "        print ('Spacy')\n",
    "        print (spacy_pairs)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to /Users/Daniele/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'preposition or conjunction, subordinating'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.data import load\n",
    "from nltk import download\n",
    "download('tagsets')\n",
    "tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
    "tagdict['IN'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           tokens Stanza NLTK Spacy\n",
      "0         Traffic     NN   JJ    NN\n",
      "1      congestion     NN   NN    NN\n",
      "2              in     IN   IN    IN\n",
      "3             the     DT   DT    DT\n",
      "4           Shire    NNP  NNP   NNP\n",
      "5              is    VBZ  VBZ   VBZ\n",
      "6         getting    VBG  VBG   VBG\n",
      "7           worse    JJR  JJR   JJR\n",
      "8               .      .    .     .\n",
      "9           After     IN   IN    IN\n",
      "10             we    PRP  PRP   PRP\n",
      "11         landed    VBD  VBD   VBD\n",
      "12             at     IN   IN    IN\n",
      "13        Baggins    NNP  NNP   NNP\n",
      "14  international     JJ   JJ    JJ\n",
      "15        airport     NN   NN    NN\n",
      "16              ,      ,    ,     ,\n",
      "17             we    PRP  PRP   PRP\n",
      "18            got    VBD  VBD   VBD\n",
      "19          stuck     JJ  VBN   VBN\n",
      "20             on     IN   IN    IN\n",
      "21            the     DT   DT    DT\n",
      "22           ring     NN   NN    NN\n",
      "23           road     NN   NN    NN\n",
      "24         around     IN   IN    IN\n",
      "25       Hobbiton    NNP  NNP   NNP\n",
      "26              .      .    .     .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Traffic congestion in the Shire is getting worse. After we landed at Baggins international airport, we got stuck on the ring road around Hobbiton.\"\n",
    "visualize_pos_results(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  tokens Stanza NLTK Spacy\n",
      "0   Back     VB   RB    RB\n",
      "1     me    PRP  PRP   PRP\n",
      "2     up     RP   RP    RP\n",
      "3      .      .    .     .\n",
      "  tokens Stanza NLTK Spacy\n",
      "0      I    PRP  PRP   PRP\n",
      "1  asked    VBD  VBD   VBD\n",
      "2   them    PRP  PRP   PRP\n",
      "3     to     TO   TO    TO\n",
      "4   back     VB   VB    VB\n",
      "5     me    PRP  PRP   PRP\n",
      "6     up     RP   RP    RP\n",
      "7      .      .    .     .\n"
     ]
    }
   ],
   "source": [
    "sentence_1='Back me up.'\n",
    "visualize_pos_results(sentence_1)\n",
    "\n",
    "sentence_2='I asked them to back me up.'\n",
    "visualize_pos_results(sentence_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When** can have many multiple PoS tags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  tokens Stanza NLTK Spacy\n",
      "0   When    WRB  WRB   WRB\n",
      "1    did    VBD  VBD   VBD\n",
      "2    you    PRP  PRP   PRP\n",
      "3   last     VB   JJ    RB\n",
      "4     go     VB   VB    VB\n",
      "5     to     IN   TO    IN\n",
      "6   Bern    NNP  NNP   NNP\n",
      "7      ?      .    .     .\n",
      "     tokens Stanza  NLTK Spacy\n",
      "0     Raise     VB    VB    VB\n",
      "1      your   PRP$  PRP$  PRP$\n",
      "2      hand     NN    NN    NN\n",
      "3      when    WRB   WRB   WRB\n",
      "4       you    PRP   PRP   PRP\n",
      "5       're    VBP   VBP   VBP\n",
      "6  finished    VBN   VBN   VBN\n"
     ]
    }
   ],
   "source": [
    "sentences=['When did you last go to Bern?',   # interrogative adverb\n",
    "'Raise your hand when you\\'re finished']  # conjunction\n",
    "\n",
    "for sentence in sentences:\n",
    "    dflist = visualize_pos_results(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wh-adverb'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagdict['WRB'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pronoun, possessive'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagdict['PRP$'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening in the following example? Which PoS tagger does better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        tokens Stanza NLTK Spacy\n",
      "0           An     DT   DT    DT\n",
      "1  experienced     JJ   JJ    JJ\n",
      "2          man     NN   NN    NN\n",
      "3       should     MD   MD    MD\n",
      "4       always     RB   RB    RB\n",
      "5          man     VB   NN    VB\n",
      "6          the     DT   DT    DT\n",
      "7         ship     NN   NN    NN\n",
      "   tokens Stanza NLTK Spacy\n",
      "0   Never     RB   RB    RB\n",
      "1     has    VBZ  VBZ   VBZ\n",
      "2      so     RB   RB    RB\n",
      "3    much     RB   JJ    RB\n",
      "4    been    VBN  VBN   VBN\n",
      "5    owed    VBN  VBN   VBN\n",
      "6      to     IN   TO    IN\n",
      "7      so     RB   RB    RB\n",
      "8    many     JJ   JJ    JJ\n",
      "9      by     IN   IN    IN\n",
      "10     so     RB   IN    RB\n",
      "11    few     JJ   JJ    JJ\n",
      "          tokens Stanza NLTK Spacy\n",
      "0              A     DT   DT    DT\n",
      "1         nation     NN   NN    NN\n",
      "2           will     MD   MD    MD\n",
      "3            not     RB   RB    RB\n",
      "4        survive     VB   VB    VB\n",
      "5        morally     RB   RB    RB\n",
      "6             or     CC   CC    CC\n",
      "7   economically     RB   RB    RB\n",
      "8           when    WRB  WRB   WRB\n",
      "9             so     RB   RB    RB\n",
      "10           few     JJ   JJ    JJ\n",
      "11          have    VBP  VBP   VBP\n",
      "12            so     RB   RB    RB\n",
      "13          much     JJ   JJ    JJ\n",
      "14           and     CC   CC    CC\n",
      "15            so     RB   RB    RB\n",
      "16          many     JJ   JJ    JJ\n",
      "17          have    VBP  VBP   VBP\n",
      "18            so     RB   RB    RB\n",
      "19        little     JJ   JJ    JJ\n"
     ]
    }
   ],
   "source": [
    "sentences=['An experienced man should always man the ship',\n",
    "'Never has so much been owed to so many by so few',\n",
    "           'A nation will not survive morally or economically \\\n",
    "when so few have so much and so many have so little']\n",
    "\n",
    "for sentence in sentences:\n",
    "    dflist = visualize_pos_results(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening in the following examples? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  tokens Stanza NLTK Spacy\n",
      "0   That     DT   DT    DT\n",
      "1   much     RB   JJ    JJ\n",
      "2     is    VBZ  VBZ   VBZ\n",
      "3   true     JJ   JJ    JJ\n",
      "4      .      .    .     .\n",
      "  tokens Stanza NLTK Spacy\n",
      "0      I    PRP  PRP   PRP\n",
      "1     do    VBP  VBP   VBP\n",
      "2    n't     RB   RB    RB\n",
      "3   know     VB   VB    VB\n",
      "4   that     RB   RB    DT\n",
      "5   much     JJ   JJ    JJ\n",
      "6      .      .    .     .\n",
      "        tokens Stanza NLTK Spacy\n",
      "0         That     DT   DT    DT\n",
      "1           's    VBZ  VBZ   VBZ\n",
      "2          not     RB   RB    RB\n",
      "3         that     RB   IN    RB\n",
      "4  interesting     JJ  VBG    JJ\n",
      "5            .      .    .     .\n",
      "  tokens Stanza NLTK Spacy\n",
      "0    How    WRB  WRB   WRB\n",
      "1   much     JJ   JJ    JJ\n",
      "2     is    VBZ  VBZ   VBZ\n",
      "3   true     JJ   JJ    JJ\n",
      "4      ?      .    .     .\n",
      "  tokens Stanza NLTK Spacy\n",
      "0   Many     JJ   JJ    JJ\n",
      "1     of     IN   IN    IN\n",
      "2   them    PRP  PRP   PRP\n",
      "3    are    VBP  VBP   VBP\n",
      "4   here     RB   RB    RB\n",
      "5      .      .    .     .\n",
      "  tokens Stanza NLTK Spacy\n",
      "0   This     DT   DT    DT\n",
      "1     is    VBZ  VBZ   VBZ\n",
      "2   mine    PRP   JJ   PRP\n",
      "3      .      .    .     .\n",
      "     tokens Stanza NLTK Spacy\n",
      "0  Everyone     NN   NN    NN\n",
      "1     knows    VBZ  NNS   VBZ\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    'That much is true.',\n",
    "    'I don\\'t know that much.', \n",
    "    'That\\'s not that interesting.',\n",
    "    'How much is true?',\n",
    "    'Many of them are here.',\n",
    "    'This is mine.',\n",
    "    'Everyone knows',\n",
    "    ]\n",
    "for sentence in sentences:\n",
    "    dflist = visualize_pos_results(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
