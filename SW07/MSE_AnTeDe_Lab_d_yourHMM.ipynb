{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnTeDe Lab D: Your own HMM PoS tagger\n",
    "\n",
    "## Session goal\n",
    "The goal of this session is build your own PoS tagger. This notebook is based on a programming assignment written by Konstantin Taranov \n",
    "and Ondrej Skopek for a Natural Language Understanding course offered at ETH Zurich in spring 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/Daniele/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown as corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We place START and STOP tags in between the individual sentences in the corpus to avoid mixing things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DET': 0.21342867108475758, 'NOUN': 0.1411405650505755, 'ADJ': 0.034339030345308684, 'VERB': 0.04513428671084758, 'ADP': 0.1228461806766655, '.': 0.08892570631321939, 'ADV': 0.0913498430415068, 'CONJ': 0.049128008371119636, 'PRT': 0.036675967910708054, 'PRON': 0.15969654691314963, 'NUM': 0.016811998604813395, 'X': 0.0005231949773282176}\n",
      "57340\n"
     ]
    }
   ],
   "source": [
    "tagged_words = []\n",
    "all_tags = []\n",
    "\n",
    "starting_p={}\n",
    "count=0\n",
    "\n",
    "sentences =corpus.tagged_sents(tagset='universal')\n",
    "\n",
    "for sent in sentences:\n",
    "    tagged_words.append((\"START\", \"START\"))\n",
    "    all_tags.append(\"START\")\n",
    "    start=True\n",
    "    for word, tag in sent:\n",
    "        try:\n",
    "            starting_p[tag]\n",
    "        except:\n",
    "            starting_p[tag]=0\n",
    "        if start:\n",
    "            starting_p[tag]=starting_p[tag]+1\n",
    "            count=count+1\n",
    "            start=False\n",
    "            \n",
    "        all_tags.append(tag)\n",
    "        tagged_words.append((tag, word))\n",
    "    tagged_words.append((\"END\", \"END\"))\n",
    "    all_tags.append(\"END\")\n",
    "\n",
    "for tag in starting_p.keys():\n",
    "    starting_p[tag]=starting_p[tag]/count\n",
    "    \n",
    "print (starting_p)\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('START', 'START'), ('DET', 'The'), ('NOUN', 'Fulton'), ('NOUN', 'County'), ('ADJ', 'Grand'), ('NOUN', 'Jury'), ('VERB', 'said'), ('NOUN', 'Friday'), ('DET', 'an'), ('NOUN', 'investigation')]\n",
      "['START', 'DET', 'NOUN', 'NOUN', 'ADJ', 'NOUN', 'VERB', 'NOUN', 'DET', 'NOUN']\n"
     ]
    }
   ],
   "source": [
    "print (tagged_words[0:10])  \n",
    "print (all_tags[0:10])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use NLTK to estimate the transition probabilities and the emission probabilities as conditional probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute $P(t_{i} | t_{i-1})= \\frac{C(t_{i-1}, t_{i})}{C(t_{i-1})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd_tags = nltk.ConditionalFreqDist(nltk.bigrams(all_tags))\n",
    "cpd_tags = nltk.ConditionalProbDist(cfd_tags, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ADV', 'ADJ') appears 7666  times\n",
      "ADV appears 56239 times\n",
      "The probability of P('ADJ'|'ADV') is roughly 0.1363\n"
     ]
    }
   ],
   "source": [
    "print(\"('ADV', 'ADJ') appears\",\n",
    "      cfd_tags['ADV']['ADJ'], \" times\" )\n",
    "\n",
    "print (\"ADV appears \"+str(cfd_tags['ADV'].N())+\" times\")\n",
    "\n",
    "\n",
    "# P('ADJ' | 'ADV')\n",
    "print(\"The probability of P('ADJ'|'ADV') is roughly\",\n",
    "      round(cpd_tags['ADV'].prob('ADJ'), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute $P(w_{i} | t_{i}) =  \\frac{C(t_{i}, w_{i})}{C(t_{i})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd_tw = nltk.ConditionalFreqDist(tagged_words)\n",
    "cpd_tw = nltk.ConditionalProbDist(cfd_tw, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of C('NOUN', 'dog') is 70\n",
      "Probability of P('dog' | 'NOUN') is 0.0002540300045725401\n"
     ]
    }
   ],
   "source": [
    "# C('dog', 'NOUN'):\n",
    "print(\"Frequency of C('NOUN', 'dog') is\",\n",
    "      cfd_tw['NOUN']['dog'])\n",
    "\n",
    "# P('dog' | 'NOUN')\n",
    "print(\"Probability of P('dog' | 'NOUN') is\",\n",
    "      cpd_tw['NOUN'].prob('dog') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here follows the code for the Viterbi algorithm, adapted from 8c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(observations, states, starting_p, transition_p, emission_p):\n",
    "    \n",
    "    # your trellis is a list of dictionaries\n",
    "    trellis = [{}]\n",
    "\n",
    "    # first column of the trellis: \n",
    "    # how likely you are to start in each state, multiplied by \n",
    "    # how likely you are to generate the initial observation \n",
    "    # from each state\n",
    "    for state in states:\n",
    "        trellis[0][state] = \\\n",
    "        {\"probability\":\\\n",
    "         starting_p[state] * emission_p[state][observations[0]],\\\n",
    "               \"previous state\": None}\n",
    "\n",
    "        \n",
    "    # for loop over the trellis columns, left to right\n",
    "    for k in range(1, len(observations)):\n",
    "\n",
    "        # add a column\n",
    "        new_column = {}\n",
    "\n",
    "        # for each row in the column\n",
    "        for state in states:\n",
    "            \n",
    "            max_path_p=0\n",
    "            \n",
    "\n",
    "            for previous_state in states:\n",
    "\n",
    "                up_to_here_p =\\\n",
    "                    trellis[k-1][previous_state][\"probability\"]*\\\n",
    "                    transition_p[previous_state][state]\n",
    "\n",
    "                if up_to_here_p > max_path_p:\n",
    "\n",
    "                    max_path_p = up_to_here_p\n",
    "\n",
    "                    prev_st_selected = previous_state\n",
    "\n",
    "                    \n",
    "\n",
    "            max_p = max_path_p * emission_p[state][observations[k]]\n",
    "\n",
    "            \n",
    "            \n",
    "            new_column[state]=\\\n",
    "            {\"probability\": max_p,\\\n",
    "             \"previous\": prev_st_selected}\n",
    "            \n",
    "        trellis.append(new_column)\n",
    "\n",
    "    max_prob = max(value[\"probability\"]\\\n",
    "                   for value in trellis[-1].values())\n",
    "\n",
    "    previous = None\n",
    "\n",
    "    return trellis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get our transmission probabilities in the same format we had them in notebook 8c. Let's check we still have the same P('ADJ'|'ADV') as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DET', 'NOUN', 'ADJ', 'VERB', 'ADP', '.', 'ADV', 'CONJ', 'PRT', 'PRON', 'NUM', 'X']\n",
      "0.13631110083749712\n"
     ]
    }
   ],
   "source": [
    "tagset = list(starting_p.keys())\n",
    "print (tagset)\n",
    "\n",
    "transition_p={}\n",
    "for tag in tagset:\n",
    "    transition_p[tag]={}\n",
    "    for conditioned_on_tag in tagset:\n",
    "        transition_p[tag][conditioned_on_tag]=\\\n",
    "        cpd_tags[conditioned_on_tag].prob(tag)\n",
    "\n",
    "\n",
    "print (transition_p['ADJ']['ADV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can use your code from 8c to get the PoS tag sequence chosen by your tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_pos_tag_sequence (trellis, observations):\n",
    "# BEGIN_REMOVE\n",
    "    import numpy as np\n",
    "    probs=[trellis[-1][state]['probability'] for state in trellis[-1].keys()]\n",
    "    chosen=np.max(np.asarray(probs))\n",
    "    chosen_state=[(state, trellis[-1][state]['previous'])\\\n",
    "                  for state in trellis[-1].keys() if trellis[-1][state]['probability']==chosen]\n",
    "\n",
    "    opt=[chosen_state[0][0]]\n",
    "    previous=chosen_state[0][1]\n",
    "\n",
    "    for t in range(len(trellis) - 2, -1, -1):\n",
    "        opt.insert(0, trellis[t + 1][previous][\"previous\"])\n",
    "        previous = trellis[t + 1][previous][\"previous\"]\n",
    "\n",
    "    result=[]    \n",
    "    for i, word in enumerate(observations):\n",
    "        result.append((word, opt[i]))\n",
    "    return result    \n",
    "        \n",
    "# END_REMOVE        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the function that we will call to run our PoS tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.tokenize as tokenize\n",
    "\n",
    "def hmm_postagger (sentence):\n",
    "    observations = tokenize.word_tokenize(sentence)\n",
    "    \n",
    "\n",
    "    emission_p={}\n",
    "    for tag in tagset:\n",
    "        emission_p[tag]={}\n",
    "        for word in observations:\n",
    "            emission_p[tag][word]=cpd_tw[tag].prob(word)\n",
    "\n",
    "    my_trellis = viterbi (observations, tagset, starting_p, transition_p, emission_p)\n",
    "    return get_pos_tag_sequence(my_trellis, observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our PoS tagger. Come up with other test sentences to see how well it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('My', 'DET'), ('dog', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('really', 'ADV'), ('good', 'ADJ'), ('dog', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"My dog is a really good dog.\"\n",
    "result = hmm_postagger (sentence)\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'prev_st_selected' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-9cb6205253d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Gondor has a very high income tax rate for married couples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmm_postagger\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-9e3a514b547c>\u001b[0m in \u001b[0;36mhmm_postagger\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0memission_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpd_tw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmy_trellis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mviterbi\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarting_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memission_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_pos_tag_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_trellis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-817fe3d011b9>\u001b[0m in \u001b[0;36mviterbi\u001b[0;34m(observations, states, starting_p, transition_p, emission_p)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mnew_column\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             {\"probability\": max_p,\\\n\u001b[0;32m---> 49\u001b[0;31m              \"previous\": prev_st_selected}\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mtrellis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'prev_st_selected' referenced before assignment"
     ]
    }
   ],
   "source": [
    "sentence = \"Gondor has a very high income tax rate for married couples.\"\n",
    "result = hmm_postagger (sentence)\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
